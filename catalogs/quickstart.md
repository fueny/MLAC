---
icon: bullseye-arrow
description: K Nearest Neighbor算法又叫KNN算法，这个算法是机器学习里面一个比较经典的算法，总体来说KNN算法是相对比较容易理解的算法
---

# KNN（K-邻近算法）

## 定义及特性

如果一个样本在特征空间中的k个最相似（即特征空间中最邻近）的样本中的大多数属于某一个类别，则该样本也属于这个类别。

KNN适用于回归和分类问题：

在分类问题中，KNN算法通过找到目标样本周围k个最相似的样本,然后根据这些邻近样本的类别信息来预测目标样本的类别。

在回归问题中，KNN算法也是类似的思路,不同的是它不是预测类别,而是预测一个连续的数值。具体做法是找到目标样本周围k个最相似的样本,然后取这些邻近样本的目标值的平均值作为目标样本的预测值。

## 原理

KNN问题多用距离来解决，下面是常用距离公式。

### 1.闵可夫斯基距离(Minkowski Distance):

闵氏距离不是一种距离，而是一组距离的定义，是对多个距离度量公式的概括性的表述。&#x20;

两个n维变量 $$p=(x_1,x_2,...,x_n)$$， $$q=(y_1,y_2,...,y_n)$$间的闵可夫斯基距离定义为:

$$
D(p,q)=(\sum_{i=1}^n |x_i-y_i|^r)^{\frac{1}{r}}
$$



